# src/pages/random_forest_manual.py

import streamlit as st
import pandas as pd
import pickle
import matplotlib.pyplot as plt
import seaborn as sns
import os
import numpy as np

from sklearn.model_selection import train_test_split, cross_val_score, learning_curve
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import (
    accuracy_score, 
    precision_score, 
    recall_score, 
    f1_score,
    roc_auc_score,
    confusion_matrix,
    classification_report,
    RocCurveDisplay
)

from src.utils.figures import mostrar_fig, save_fig_to_disk
from src.utils.palette import PALETA


# ===============================================================
# ENTRENAMIENTO MANUAL RANDOM FOREST
# ===============================================================
def show_random_forest_manual():

    st.subheader("Entrenamiento Manual")
    st.markdown(
        '<p style="font-size: 22px;">Entren√° manualmente un modelo '
        '<span style="color: orange; font-weight:600;">Random Forest</span> ajustando los par√°metros.</p>',
        unsafe_allow_html=True
    )

    # ===============================================================
    # 1Ô∏è‚É£ CARGA DEL DATASET
    # ===============================================================
    st.markdown("### 1. Cargar Dataset Procesado")

    try:
        # Se intenta cargar el dataset procesado previamente
        df = pd.read_csv("data/dataset_ml_productos.csv")
        st.success("Dataset cargado correctamente.")
        
        # Se muestra un preview de las primeras filas
        st.dataframe(df.head())
        
    except FileNotFoundError:
        # Detiene la ejecuci√≥n si el dataset no existe
        st.error("‚ö†Ô∏è No se encontr√≥ el archivo data/dataset_ml_productos.csv.")
        st.stop()

    # ===============================================================
    # 2Ô∏è‚É£ TARGET Y FEATURES - CORREGIDO
    # ===============================================================
    st.markdown("### 2. Variable Objetivo")

    # Variable que se quiere predecir
    target = "nivel_demanda"
    
    # Validaci√≥n de existencia del target
    if target not in df.columns:
        st.error(f"‚ùå No se encuentra la columna '{target}' en el dataset")
        st.stop()
    
    # Selecci√≥n autom√°tica de features eliminando columnas no deseadas
    features= [col for col in df.columns 
              if col not in ['nivel_demanda', 'total_unidades', 
                            'total_ventas', 'unidades_por_transaccion']]
    
    # Informaci√≥n al usuario
    st.info(f"**Target:** `{target}` (clasificaci√≥n multiclase: 0=baja, 1=media, 2=alta)")
    st.write(f"**Features:** {len(features)} variables")

    # ===============================================================
    # 3Ô∏è‚É£ PAR√ÅMETROS DEL MODELO
    # ===============================================================
    st.markdown("### 3. Configuraci√≥n del Modelo")

    # Distribuci√≥n visual en dos columnas
    col1, col2 = st.columns(2)

    with col1:
        # Hiperpar√°metros principales
        n_estimators = st.slider("Cantidad de √°rboles", 50, 300, 200)
        max_depth = st.slider("Profundidad m√°xima", 2, 20, 15)
        
        # Balanceo autom√°tico basado en distribuci√≥n del target
        balancear = st.checkbox("Balancear clases", value=True)

    with col2:
        # Proporci√≥n del conjunto de test
        test_size = st.slider("Tama√±o del Test (%)", 10, 40, 31) / 100
        
        # Semilla para reproducibilidad
        random_state = st.number_input("Random State", value=789)

    # ===============================================================
    # 4Ô∏è‚É£ VALIDACIONES
    # ===============================================================
    st.markdown("### 4. Validaciones del Dataset")

    # Validaci√≥n de valores faltantes
    if df.isna().sum().sum() > 0:
        st.error("‚ùå Hay valores faltantes en el dataset")
        st.stop()
    else:
        st.success("‚úÖ No hay valores faltantes")

    # --- Visualizaci√≥n de distribuci√≥n del target ---
    st.subheader("Distribuci√≥n del Target")
    distribucion = df[target].value_counts().sort_index()
    st.dataframe(distribucion.rename_axis("Clase").reset_index(name="Cantidad"))

    fig, ax = plt.subplots(figsize=(8, 4))

    sns.barplot(
        x=distribucion.index, 
        y=distribucion.values, 
        palette=list(PALETA.values()),  
        ax=ax
    )
    
    # Est√©tica del gr√°fico
    ax.set_title(
        "Distribuci√≥n de Clases - Nivel de Demanda",
        fontsize=16, fontweight="bold", color=PALETA["secundario"],
        pad=15
    )
    ax.set_xlabel("Nivel de Demanda (0=baja, 1=media, 2=alta)", fontsize=12, fontweight="bold")
    ax.set_ylabel("Cantidad de Productos", fontsize=12, fontweight="bold")
    ax.grid(alpha=0.2)
    
    mostrar_fig(fig)

    # Advertencia por dataset peque√±o
    if len(df) < 100:
        st.warning(
            "‚ö†Ô∏è El dataset es peque√±o (menos de 100 filas). "
            "Para obtener un modelo m√°s robusto y con mejor capacidad de generalizaci√≥n, "
            "ser√≠a recomendable contar con m√°s datos."
        )

    # ===============================================================
    # 5Ô∏è‚É£ ENTRENAR MODELO
    # ===============================================================
    st.markdown("### 5. Entrenar Modelo")

    # Solo entrena el modelo si se presiona el bot√≥n
    if st.button("üéØ Entrenar modelo Random Forest", type="primary"):

        with st.spinner("Entrenando modelo..."):
            
            # Separaci√≥n de datos en X (features) e y (target)
            X = df[features]
            y = df[target]

            # Divisi√≥n del dataset respetando la proporci√≥n original de clases
            X_train, X_test, y_train, y_test = train_test_split(
                X, y, 
                test_size=0.31,     # Mismo que PyCaret
                random_state=789,   # Mismo que PyCaret
                stratify=y
            )
            
            # Configuraci√≥n del modelo con hiperpar√°metros seleccionados           
            model = RandomForestClassifier(
                n_estimators=n_estimators,  # M√°s √°rboles, 200
                max_depth=max_depth,        # M√°s profundidad, 15 
                min_samples_split=5,        # Evita overfitting
                min_samples_leaf=2,
                max_features='sqrt',        # Mejor generalizaci√≥n
                class_weight='balanced',
                random_state=789,
                n_jobs=-1
            )
            
            # Entrenamiento del modelo
            model.fit(X_train, y_train)

        st.success("‚úÖ Modelo entrenado correctamente")

        # ===============================================================
        # 6Ô∏è‚É£ VALIDACI√ìN CRUZADA
        # ===============================================================
        st.markdown("### 6. Validaci√≥n Cruzada (5 folds)")
        
        # Ajuste din√°mico del n√∫mero de folds:
        # Para datasets peque√±os, usar muchos folds puede causar errores.
        # Se define la cantidad como el m√≠nimo entre 5 y (filas/3), garantizando suficientes datos por fold.
        cv_folds = min(5, len(df) // 3)
        
        # Validaci√≥n cruzada para Accuracy.
        # cross_val_score entrena el modelo "cv_folds" veces con diferentes particiones.
        cv_accuracy = cross_val_score(model, X, y, cv=cv_folds, scoring="accuracy")
        
        # Validaci√≥n cruzada para F1 Weighted (maneja clases desbalanceadas)
        cv_f1 = cross_val_score(model, X, y, cv=cv_folds, scoring="f1_weighted")

        # Tabla resumen por fold
        cv_table = pd.DataFrame({
            "Fold": range(1, cv_folds + 1),
            "Accuracy": cv_accuracy,
            "F1 Weighted": cv_f1
        })

        st.dataframe(cv_table.style.format("{:.4f}"))

        # Mostrar m√©tricas promedio
        col1, col2 = st.columns(2)
        with col1:
            st.metric("Accuracy Promedio", f"{cv_accuracy.mean():.4f}")
        with col2:
            st.metric("F1 Score Promedio", f"{cv_f1.mean():.4f}")

        # ===============================================================
        # 7Ô∏è‚É£ M√âTRICAS DEL TEST
        # ===============================================================
        st.markdown("### 7. M√©tricas del Test")

        # Predicciones sobre los datos de test
        y_pred = model.predict(X_test)

        # Tabla con m√©tricas cl√°sicas de clasificaci√≥n
        metricas = pd.DataFrame({
            "M√©trica": ["Accuracy", "Precision", "Recall", "F1 Score"],
            "Valor": [
                accuracy_score(y_test, y_pred),
                precision_score(y_test, y_pred, average='weighted'),  # pondera seg√∫n frecuencia de clases
                recall_score(y_test, y_pred, average='weighted'), 
                f1_score(y_test, y_pred, average='weighted'),
            ]
        })

        st.dataframe(metricas.style.format({"Valor": "{:.4f}"}))

        # ===============================================================
        # 8Ô∏è‚É£ CURVA ROC
        # ===============================================================
        st.markdown("### 8. Curva ROC / AUC")

        # Para clasificaci√≥n multiclase, se usa el enfoque One-vs-Rest (OvR)
        y_proba = model.predict_proba(X_test)
        
        # AUC macro promedia el AUC de cada clase
        auc_macro = roc_auc_score(y_test, y_proba, multi_class="ovr", average="macro")

        fig, ax = plt.subplots(figsize=(8, 6))
        colores = plt.cm.tab10.colors

        # Dibujar una curva ROC por cada clase
        for i, clase in enumerate(model.classes_):
            RocCurveDisplay.from_predictions(
                y_test == clase,    # binariza la clase actual
                y_proba[:, i],      # probabilidades de esa clase
                name=f"Clase {clase}",
                ax=ax,
                color=colores[i]
            )

        # Est√©tica del gr√°fico
        ax.set_title(
                "Curvas ROC (Multiclase - One vs Rest)",
                fontsize=16, fontweight="bold", color=PALETA["secundario"],
                pad=15
            )
        ax.set_xlabel("Tasa de Falsos Positivos (FPR)", fontsize=12, fontweight="bold")
        ax.set_ylabel("Tasa de Verdaderos Positivos (TPR)", fontsize=12, fontweight="bold")
        ax.grid(alpha=0.2)
        
        ax.legend(
                title="Clases",
                fontsize=10,
                title_fontsize=11,
                loc="lower right",
                frameon=True
            )
        
        save_fig_to_disk(fig)
        mostrar_fig(fig)

        # Valor del AUC macro
        st.write(f"**AUC (macro):** {auc_macro:.4f}")

        # ===============================================================
        # 9Ô∏è‚É£ MATRIZ DE CONFUSI√ìN
        # ===============================================================
        st.markdown("### 9. Matriz de Confusi√≥n")

        # Calcular matriz de confusi√≥n
        cm = confusion_matrix(y_test, y_pred)
        labels = model.classes_

        fig, ax = plt.subplots(figsize=(5, 5))
        
        # Heatmap con anotaciones
        sns.heatmap(
            cm,
            annot=True,
            fmt="d",
            cmap=sns.diverging_palette(25, 220, s=70, l=40, as_cmap=True), 
            center=0,
            xticklabels=labels,
            yticklabels=labels,
            cbar=True,
            square=True,  
            linewidths=0.5,  
            linecolor='white', 
            cbar_kws={'shrink': 0.6}, 
            ax=ax
        )       
        
        # Estilo del gr√°fico
        ax.set_title("Matriz de Confusi√≥n", fontsize=14, fontweight="bold", color=PALETA["secundario"])
        ax.set_xlabel("Predicci√≥n", fontsize=12, fontweight="bold")
        ax.set_ylabel("Real", fontsize=12, fontweight="bold")
        
        save_fig_to_disk(fig)
        mostrar_fig(fig, ancho=500)

        # ===============================================================
        # üî∏ IMPORTANCIAS
        # ===============================================================
        st.markdown("### 10. Importancia de Variables")

        # Obtener importancia entregada por el Random Forest
        importances = pd.DataFrame({
            "variable": features,
            "importancia": model.feature_importances_
        }).sort_values("importancia", ascending=False)

        st.dataframe(importances)

        fig, ax = plt.subplots(figsize=(8, 6))
        
        # Gr√°fico de barras horizontal
        sns.barplot(
            data=importances.sort_values("importancia", ascending=True),
            x="importancia",
            y="variable",
            color=PALETA["acento1"],
            ax=ax
        )
        
        # T√≠tulos y etiquetas
        ax.set_title(
            "Importancia de Variables",
            fontsize=14,
            fontweight="bold",
            color=PALETA["secundario"]
        )
        ax.set_xlabel("Importancia", fontsize=12,fontweight="bold")
        ax.set_ylabel("Variables", fontsize=12,fontweight="bold")
        
        save_fig_to_disk(fig)
        mostrar_fig(fig)


        # ===============================================================
        # 1Ô∏è‚É£1Ô∏è‚É£ Classification Report (M√©tricas por clase)
        # ===============================================================
        st.markdown("### 12. M√©tricas por Clase (Classification Report)")

        st.info("""
        **Interpretaci√≥n del Classification Report:**

        - **Precision**: De los productos que predije como X demanda, ¬øcu√°ntos realmente eran de esa demanda?
        - **Recall**: De todos los productos que realmente son de X demanda, ¬øcu√°ntos logr√© identificar?
        - **F1-Score**: Balance entre Precision y Recall (media arm√≥nica)

        **üî∏ Objetivo ideal**: Valores altos y balanceados en las 3 m√©tricas para todas las clases.
        """)

        # Obtener reporte en dict
        report = classification_report(
            y_test, y_pred, 
            output_dict=True, 
            zero_division=0
        )

        # Convertir a DataFrame solo para clases
        report_df = pd.DataFrame(report).transpose()
        report_df = report_df.loc[[str(c) for c in model.classes_], ["precision", "recall", "f1-score"]]

        # Mostrar tabla
        st.dataframe(
            report_df.style.format("{:.3f}")
        )

        # An√°lisis autom√°tico de fortalezas y debilidades
        st.markdown("#### An√°lisis por Clase:")
        
        for clase in model.classes_:
            clase_str = str(clase)
            precision = report_df.loc[clase_str, "precision"]
            recall = report_df.loc[clase_str, "recall"]
            f1 = report_df.loc[clase_str, "f1-score"]
            
            if clase == 0:
                nombre_clase = "Baja Demanda"
            elif clase == 1:
                nombre_clase = "Media Demanda" 
            else:
                nombre_clase = "Alta Demanda"
            
            # Evaluaci√≥n autom√°tica
            if f1 >= 0.7:
                emoji = "‚úÖ"
                estado = "BUENO"
            elif f1 >= 0.5:
                emoji = "‚ö†Ô∏è" 
                estado = "REGULAR"
            else:
                emoji = "‚ùå"
                estado = "A MEJORAR"
            
            st.write(f"{emoji} **{nombre_clase}**: F1-Score = {f1:.3f} ({estado})")
            

        # Heatmap
        fig, ax = plt.subplots(figsize=(5, 5))  
        sns.heatmap(
            report_df,
            annot=True,
            fmt=".3f",
            cmap=sns.diverging_palette(25, 220, s=70, l=40, as_cmap=True), 
            center=0,
            xticklabels=["Precision", "Recall", "F1-Score"],
            yticklabels=labels,
            cbar=True,
            square=True,  
            linewidths=0.5,  
            linecolor='white', 
            cbar_kws={'shrink': 0.6},  
            ax=ax
        )
        
        ax.set_title(
            "Classification Report - M√©tricas por Clase",
            fontsize=14,
            fontweight="bold",
            color=PALETA["secundario"]
        )

        ax.set_xlabel("M√©trica", fontsize=12, fontweight="bold")
        ax.set_ylabel("Clase", fontsize=12, fontweight="bold")

        # Ajustar tama√±o de las etiquetas de los ejes
        ax.tick_params(axis='both', labelsize=9)
        
        plt.tight_layout()  # Ajustar m√°rgenes autom√°ticamente
        
        save_fig_to_disk(fig)
        mostrar_fig(fig, ancho=500)

        # ===============================================================
        # 1Ô∏è‚É£2Ô∏è‚É£ Curva de Aprendizaje (Learning Curve)
        # ===============================================================
        st.markdown("### 13. Curva de Aprendizaje (Learning Curve)")
        
        st.info("""
        **Interpretaci√≥n de la Curva de Aprendizaje:**

        - **L√≠nea AZUL (Entrenamiento)**: Performance del modelo en los datos de entrenamiento
        - **L√≠nea VERDE (Validaci√≥n)**: Performance en datos no vistos (generalizaci√≥n)

        **üî∏ Patrones a observar:**
        - **Curvas convergentes**: Modelo generaliza bien
        - **Brecha grande**: Posible overfitting (modelo muy complejo)  
        - **Ambas bajas**: Underfitting (modelo muy simple)
        - **Todas suben**: M√°s datos podr√≠an ayudar
        """)

        train_sizes, train_scores, test_scores = learning_curve(
            model, X, y,
            cv=cv_folds,
            train_sizes=np.linspace(0.2, 1.0, 5),
            scoring="accuracy",
            n_jobs=-1
        )

        train_mean = train_scores.mean(axis=1)
        test_mean = test_scores.mean(axis=1)

        fig, ax = plt.subplots(figsize=(8, 5))
        ax.plot(train_sizes, train_mean, marker="o", label="Entrenamiento")
        ax.plot(train_sizes, test_mean, marker="o", label="Validaci√≥n")

        ax.set_title(
            "Learning Curve - Accuracy",
            fontsize=14,
            fontweight="bold",
            color=PALETA["secundario"]
        )

        ax.set_xlabel("Cantidad de muestras de entrenamiento", fontsize=12, fontweight="bold")
        ax.set_ylabel("Accuracy", fontsize=12, fontweight="bold")
        ax.grid(alpha=0.2)
        ax.legend()


        # An√°lisis autom√°tico de la curva
        brecha_final = train_mean[-1] - test_mean[-1]
        accuracy_final = test_mean[-1]

        st.markdown("#### üîç Diagn√≥stico de la Curva:")

        if brecha_final < 0.1:
            st.write(f"‚úÖ **BUENA GENERALIZACI√ìN**: Brecha peque√±a ({brecha_final:.3f}) entre entrenamiento y validaci√≥n")
        elif brecha_final < 0.2:
            st.write(f"‚ö†Ô∏è **GENERALIZACI√ìN MODERADA**: Brecha moderada ({brecha_final:.3f}) - considerar regularizaci√≥n")
        else:
            st.write(f"‚ùå **POSIBLE OVERFITTING**: Brecha grande ({brecha_final:.3f}) - modelo muy complejo para los datos")

        if accuracy_final > 0.7:
            st.write(f"üéØ **ALTA PRECISI√ìN**: Accuracy final de {accuracy_final:.3f}")
        elif accuracy_final > 0.6:
            st.write(f"üìä **PRECISI√ìN ACEPTABLE**: Accuracy final de {accuracy_final:.3f}")
        else:
            st.write(f"üîß **PRECISI√ìN A MEJORAR**: Accuracy final de {accuracy_final:.3f}")
            
        save_fig_to_disk(fig)    
        mostrar_fig(fig)


        # ===============================================================
        # 1Ô∏è‚É£3Ô∏è‚É£ DESCARGAR MODELO
        # ===============================================================
        st.markdown("### 11. Descargar Modelo Entrenado")

        # Convertir modelo a bytes para descarga
        model_bytes = pickle.dumps(model)
        
        st.download_button(
            "üì• Descargar Modelo (.pkl)",
            model_bytes,
            "random_forest_manual.pkl",
            mime="application/octet-stream"
        )

        st.success("‚úÖ Proceso completado. Modelo listo para usar.")
        
        # Guardado autom√°tico en /models
        os.makedirs("models", exist_ok=True)    # Crear carpeta 'models' si no existe

        ruta_modelo = f"models/random_forest_manual.pkl"

        # Guardar el modelo entrenado
        with open(ruta_modelo, "wb") as f:
            pickle.dump(model, f)

        st.info(f"üìÅ Modelo guardado autom√°ticamente en: `{ruta_modelo}`")    