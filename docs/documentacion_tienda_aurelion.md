# üõíProyecto Tienda Aurelion ‚Äì Documentaci√≥n t√©cnica

### üìö √çndice de contenidos

- [üõíProyecto Tienda Aurelion ‚Äì Documentaci√≥n t√©cnica](#proyecto-tienda-aurelion--documentaci√≥n-t√©cnica)
    - [üìö √çndice de contenidos](#-√≠ndice-de-contenidos)
    - [Tema](#tema)
    - [Problema](#problema)
    - [Soluci√≥n](#soluci√≥n)
    - [Fuente](#fuente)
    - [Datasets: definici√≥n, columnas y tipos](#datasets-definici√≥n-columnas-y-tipos)
    - [Estructura](#estructura)
    - [Informaci√≥n](#informaci√≥n)
    - [Pasos](#pasos)
    - [Pseudoc√≥digo](#pseudoc√≥digo)
    - [Diagrama del flujo üü°üü°üü°üü°üü°üü°üü°üü°üü°üü°üü°üü°](#diagrama-del-flujo-)
    - [Interpretaciones EDA ‚Äì Visualizaciones](#interpretaciones-eda--visualizaciones)
      - [üî∏ Gr√°fica: distribucion\_numericas](#-gr√°fica-distribucion_numericas)
      - [üî∏ Gr√°fica: correlacion](#-gr√°fica-correlacion)
      - [üî∏ Gr√°fica: ventas\_total\_por\_mes](#-gr√°fica-ventas_total_por_mes)
      - [üî∏ Gr√°fica: relacion\_cantidad](#-gr√°fica-relacion_cantidad)
      - [üî∏ Gr√°fica: outliers](#-gr√°fica-outliers)
    - [Preprocesamiento para Machine Learning](#preprocesamiento-para-machine-learning)
    - [AutoML: Benchmarking con PyCaret](#automl-benchmarking-con-pycaret)
    - [Entrenamiento Manual: Random Forest](#entrenamiento-manual-random-forest)

---

### Tema

An√°lisis y consulta interactiva de datos de ventas de la Tienda Aurelion, una tienda minorista que desea comprender mejor el comportamiento de sus ventas, productos y clientes.

### Problema

La Tienda Aurelion enfrenta dificultades para mantener un equilibrio adecuado entre el stock disponible y la demanda real de los productos. Esto genera dos problemas recurrentes:

  - _Rupturas de stock_: cuando un producto se agota y no puede ser vendido.
  - _Exceso de inventario_: cuando se compran productos que permanecen sin rotaci√≥n durante mucho tiempo.

Ambas situaciones impactan negativamente en la rentabilidad del negocio:

  - Las rupturas de stock reducen las ventas y afectan la satisfacci√≥n del cliente.
  - El exceso de inventario genera costos de almacenamiento innecesarios.

### Soluci√≥n

Desarrollar un programa en Python y Streamlit que permita interactuar con los datos y consultar de forma sencilla informaci√≥n relevante. Utilizar los datos hist√≥ricos de ventas, clientes y productos para:

  - Analizar la demanda real de cada producto.
  - Identificar los productos de mayor y menor rotaci√≥n.
  - Estimar la demanda futura promedio mensual.
  - Proporcionar informaci√≥n visual que ayude a tomar decisiones de compra y reposici√≥n m√°s inteligentes.

**An√°lisis que se puede realizar**

1. Ventas totales por producto y mes.
2. Ranking de productos m√°s vendidos.
3. Relaci√≥n entre stock disponible y ventas promedio.
4. Productos con ventas decrecientes (riesgo de exceso de stock).
5. Productos con ventas crecientes (riesgo de ruptura de stock).
6. Predicci√≥n de demanda promedio mediante una regresi√≥n lineal simple.

**Resultado esperado**

Una aplicaci√≥n en Streamlit que permita:

   - Visualizar m√©tricas de ventas y rotaci√≥n.
   - Detectar los productos cr√≠ticos para reposici√≥n.
   - Consultar la documentaci√≥n del proyecto.


---

### Fuente

Su origen es secundario, los datasets fueron provistos por Guayerd dentro del programa de Fundamentos de Inteligencia Artificial que desarrolla junto a IBM.

_Nota_: Estos datasets son de car√°cter did√°ctico y se proporcionan solo con fines de prueba y aprendizaje, para poder estudiar y practicar el an√°lisis de datos y la implementaci√≥n de modelos.

---

### Datasets: definici√≥n, columnas y tipos

| Dataset | Descripci√≥n breve | Columnas | Tipo / Escala |
|----------|------------------|-----------|----------------|
| **clientes.xlsx** | Informaci√≥n de los clientes | id_cliente<br>nombre_cliente<br>email<br>ciudad<br>fecha_alta | int64 (Raz√≥n)<br>object (Nominal)<br>object (Nominal)<br>object (Nominal)<br>datetime64 (Intervalo) |
| **productos.xlsx** | Informaci√≥n de los productos | id_producto<br>nombre_producto<br>categoria<br>precio_unitario | int64 (Raz√≥n)<br>object (Nominal)<br>object (Nominal)<br>int64 (Raz√≥n) |
| **ventas.xlsx** | Registro de cada venta realizada | id_venta<br>fecha<br>id_cliente<br>nombre_cliente<br>email<br>medio_pago | int64 (Raz√≥n)<br>datetime64 (Intervalo)<br>int64 (Raz√≥n)<br>object (Nominal)<br>object (Nominal)<br>object (Nominal) |
| **detalle_ventas.xlsx** | Detalle de cada producto vendido | id_venta<br>id_producto<br>nombre_producto<br>cantidad<br>precio_unitario<br>importe | int64 (Raz√≥n)<br>int64 (Raz√≥n)<br>object (Nominal)<br>int64 (Raz√≥n)<br>int64 (Raz√≥n)<br>int64 (Raz√≥n) |

**Comentarios:**

- **PK (Primary Key):** identificador √∫nico de cada registro.  
- **FK (Foreign Key):** columna que referencia la PK de otro dataset.  
- `id_cliente`, `id_producto` y `id_venta` son **PK** en sus respectivas tablas.  
- `ventas.id_cliente` referencia a `clientes.id_cliente`.  
- `detalle_ventas.id_venta` referencia a `ventas.id_venta`.  
- `detalle_ventas.id_producto` referencia a `productos.id_producto`.  

---

### Estructura

Cada dataset es estructurado; se organiza en filas que representan registros individuales y columnas que representan atributos de inter√©s para el an√°lisis. Contienen datos tanto cuantitativos como cualitativos. Todos ellos en formato .xlsx (Excel).

---

### Informaci√≥n

üî∏ **Nombre del programa:** Proyecto Tienda Aurelion

üî∏ **Objetivo:**
  Permitir la exploraci√≥n interactiva de los datos de ventas, clientes y productos de la tienda, proporcionados en los siguientes dataset:
  - `clientes.xlsx`
  - `productos.xlsx`
  - `ventas.xlsx` 
  - `detalle_ventas.xlsx`
   
  Estos archivos fueron unificados en un √∫nico dataset integrado denominado `df_tienda_aurelion.csv`, que concentra toda la informaci√≥n relevante para su an√°lisis. 
   
  Adem√°s, la aplicaci√≥n muestra la documentaci√≥n, el pseudoc√≥digo y los diagramas de flujo del proyecto.

üî∏ **Lenguaje y librer√≠as utilizadas**

  - `Python 3.9`
  - Librer√≠as principales:
    - `streamlit` (interfaz web)
    - `pandas` (manipulaci√≥n de datos)
    - `Pillow` / `PIL` (manipulaci√≥n de im√°genes)
    - `numpy` (c√°lculo num√©rico)
    - `matplotlib`, `seaborn` (visualizaci√≥n)
    - `ydata-profiling` (EDA automatizado)
    - `streamlit-pandas-profiling` (integraci√≥n de perfiles en Streamlit)
  - Librer√≠as para Machine Learning:
    - `pycaret` (AutoML / benchmarking)
    - `scikit-learn` (`sklearn`: preprocesamiento, modelos y m√©tricas)
    - `joblib` / `pickle` (serializaci√≥n de modelos)
  - Utilidades y sistema de archivos:
    - `os`, `pathlib` (gesti√≥n de rutas y archivos)
    - `pickle` (serializaci√≥n en memoria/file)
  - Observaci√≥n: Algunas dependencias se usan indirectamente (p. ej. `openpyxl` como motor de `pandas.read_excel`).

üî∏ **Entrada de datos**
  - Archivos Excel: `clientes.xlsx`, `productos.xlsx`, `ventas.xlsx`, `detalle_ventas.xlsx`
  - Archivo de documentaci√≥n: `documentacion_tienda_aurelion.md`

üî∏ **Salida / Visualizaci√≥n**
  - Interfaz web interactiva con men√∫ lateral
  - Expanders utilizados en la secci√≥n Ver documentaci√≥n para mostrar de forma organizada el contenido t√©cnico (contexto, datasets, metodolog√≠a, pseudoc√≥digo y diagrama de flujo).
  - Tablas de datos y res√∫menes estad√≠sticos

üî∏ **Funcionalidades principales**
  - **Informaci√≥n General**: Vista previa de cada dataset, tipos de datos, metadatos y estad√≠sticas b√°sicas.
  - **Estad√≠sticas Descriptivas**: An√°lisis detallado mediante `pandas.describe(include="all")` con visualizaciones personalizadas:
    - Distribuci√≥n de variables num√©ricas y categ√≥ricas
    - Matrices de correlaci√≥n
    - Gr√°ficos espec√≠ficos por dataset (series temporales, distribuciones, etc.)
  - **EDA Automatizado**: An√°lisis exploratorio completo utilizando `ydata-profiling`:
    - Perfilado autom√°tico de variables
    - Detecci√≥n de correlaciones y patrones
    - An√°lisis de valores faltantes y cardinalidad
  - **EDA Diagn√≥stico**: An√°lisis en profundidad del dataset unificado:
    - Limpieza y preparaci√≥n de datos
    - Detecci√≥n y an√°lisis de outliers
    - Visualizaciones avanzadas de series temporales
    - Identificaci√≥n de productos top y patrones de venta
  - **Preprocesamiento ML**: Herramientas interactivas para preparar datos antes del modelado:
    - Selecci√≥n de objetivo (`target`) y variables predictoras
    - Imputaci√≥n de valores faltantes (media/mediana/moda)
    - Codificaci√≥n de variables categ√≥ricas (`one-hot`, `ordinal`)
    - Escalado de variables num√©ricas (`StandardScaler`, `MinMaxScaler`)
    - Selecci√≥n/filtrado de features y exportaci√≥n del dataset preprocesado a CSV
  - **ML Automatizado (AutoML)**: Benchmarking y selecci√≥n autom√°tica de modelos (PyCaret):
    - Inicializaci√≥n del experimento (`setup`) con normalizaci√≥n y control de multicolinealidad
    - Comparaci√≥n autom√°tica de modelos (`compare_models`) y visualizaci√≥n de m√©tricas
    - Exportaci√≥n y descarga del mejor modelo encontrado
  - **Entrenamiento Manual (Random Forest)**: Entrenamiento y evaluaci√≥n controlada:
    - Ajuste interactivo de hiperpar√°metros (n_estimators, max_depth, class_weight, etc.)
    - Validaci√≥n cruzada, m√©tricas de test, curvas ROC y matriz de confusi√≥n
    - Interpretaci√≥n mediante `feature_importances_` y curvas de aprendizaje
    - Guardado y descarga del modelo (`joblib`/`pickle`)
  - **Documentaci√≥n Interactiva**: Acceso organizado a la documentaci√≥n t√©cnica del proyecto
  - **Exportaci√≥n de artefactos**: Guardado autom√°tico de figuras en `assets/plots` y modelos en `models/`

üî∏ **Estructura del programa**
  - **Carga y Unificaci√≥n**: 
    - Funci√≥n `load_dataset()` con cach√© de Streamlit
    - Generaci√≥n autom√°tica del dataset unificado mediante `load_and_merge_datasets()`
  - **Men√∫ Principal**: Radio buttons en la barra lateral con las opciones:
    - Informaci√≥n General
    - Estad√≠sticas
    - EDA Automatizado
    - EDA Diagn√≥stico
    - Preprocesamiento ML
    - ML Automatizado
    - Entrenamiento Random Forest
    - Ver Documentaci√≥n
  - **M√≥dulos Organizados**:
    - Cargadores de datos (`data_loader.py`)
    - P√°ginas separadas por funcionalidad (`pages/`)
    - Utilidades de visualizaci√≥n (`utils/`)

---

### Pasos

<h5>1Ô∏è‚É£ <b>Inicio de la aplicaci√≥n</b></h5>

- Se inicializa Streamlit y se configura la p√°gina (t√≠tulo, √≠cono y dise√±o).
- Se muestra el logotipo de la tienda junto al encabezado principal de la interfaz.

<h5>2Ô∏è‚É£ <b>Carga de datasets</b></h5>

- Se leen los archivos Excel: `clientes.xlsx`, `productos.xlsx`, `ventas.xlsx` y `detalle_ventas.xlsx` mediante **pandas**.
- Cada archivo se carga en un **DataFrame** independiente.
- La funci√≥n de carga se **almacena en cach√©** (`st.cache_data`) para optimizar el rendimiento y evitar recargas innecesarias.

<h5>3Ô∏è‚É£ <b>Men√∫ principal</b></h5>

- Se implementa mediante radio buttons en la barra lateral, ofreciendo secciones principales:
  - **Informaci√≥n General**: Exploraci√≥n b√°sica de datasets
  - **Estad√≠sticas**: An√°lisis descriptivo y visualizaciones
  - **EDA Automatizado**: Perfilado completo de datos
  - **EDA Diagn√≥stico**: An√°lisis detallado y visualizaciones
  - **Preprocesamiento ML**: Limpieza, transformaci√≥n y preparaci√≥n del dataset para entrenamiento.
  - **AutoML (Benchmark)**: Comparaci√≥n autom√°tica de m√∫ltiples modelos y selecci√≥n del mejor rendimiento.
  - **Entrenamiento Manual (Random Forest)**: Configuraci√≥n, entrenamiento y evaluaci√≥n detallada del modelo Random Forest.
  - **Ver Documentaci√≥n**: Acceso a documentaci√≥n t√©cnica

<h5>4Ô∏è‚É£ <b>Opci√≥n: Informaci√≥n General</b></h5>

  - Interfaz de selecci√≥n de dataset mediante selectbox
  - Para cada archivo seleccionado muestra:
    - Metadatos: fecha de modificaci√≥n y tama√±o
    - Vista previa de registros mediante `head()`
    - Estructura detallada: tipos de datos y columnas
    - Resumen: dimensiones y cantidad de registros
  - Informaci√≥n organizada en expanders para mejor navegaci√≥n

<h5>5Ô∏è‚É£ <b>Opci√≥n 2: Estad√≠sticas</b></h5>

   - Selecci√≥n interactiva del dataset a analizar
   - An√°lisis estad√≠stico completo que incluye:
     - Estad√≠sticas descriptivas via `describe(include="all")`
     - An√°lisis de valores nulos y √∫nicos
     - Visualizaciones espec√≠ficas seg√∫n tipo de datos:
       ‚Ä¢ Variables num√©ricas: histogramas y boxplots
       ‚Ä¢ Variables categ√≥ricas: gr√°ficos de barras y pie
       ‚Ä¢ Series temporales: evoluci√≥n y tendencias

<h5>6Ô∏è‚É£ <b>Opci√≥n 3: EDA Automatizado</b></h5>

   - Generaci√≥n autom√°tica del dataset unificado si no existe
   - Creaci√≥n de un reporte interactivo completo usando `ydata-profiling`
   - Visualizaci√≥n integrada mediante `streamlit-pandas-profiling`
   - An√°lisis autom√°tico de:
     ‚Ä¢ Distribuciones y estad√≠sticas
     ‚Ä¢ Correlaciones entre variables
     ‚Ä¢ Valores faltantes y duplicados
     ‚Ä¢ Alertas y recomendaciones

<h5>7Ô∏è‚É£ <b>Opci√≥n 4: EDA Diagn√≥stico</b></h5>

   - An√°lisis profundo del dataset unificado
   - Proceso de limpieza y preparaci√≥n de datos
   - Generaci√≥n de visualizaciones avanzadas:
     ‚Ä¢ Matrices de correlaci√≥n
     ‚Ä¢ Series temporales de ventas
     ‚Ä¢ An√°lisis de outliers
     ‚Ä¢ Rankings y patrones de venta
   - Guardado autom√°tico de gr√°ficos en `assets/plots`

<h5>8Ô∏è‚É£ <b>Opci√≥n: Preprocesamiento ML</b></h5>

  - Permitir seleccionar objetivo (`target`) y variables predictoras.
  - Opciones interactivas de preprocesamiento:
    - Manejo de nulos: imputaci√≥n por media/mediana/moda.
    - Codificaci√≥n de categ√≥ricas: `one-hot` o `ordinal`.
    - Escalado de num√©ricos: `StandardScaler` o `MinMaxScaler`.
    - Selecci√≥n de features (filtro o m√©todos autom√°ticos).
  - Configurar `train/test split` y semilla (seed).
  - Mostrar resumen del dataset preprocesado y permitir exportarlo como CSV.

<h5>9Ô∏è‚É£ <b>Opci√≥n: AutoML (Benchmark)</b></h5>

  - Cargar dataset preprocesado.
  - Inicializar experimento con PyCaret: `setup()` indicando `target`, `normalize`, `session_id`, etc.
  - Ejecutar `compare_models()` para obtener ranking por la m√©trica escogida (AUC/Accuracy/RMSE seg√∫n caso).
  - Mostrar top-N modelos, m√©tricas y gr√°ficos comparativos.
  - Permitir guardar el mejor modelo y exportar su configuraci√≥n.

<h5>1Ô∏è‚É£0Ô∏è‚É£ <b>Opci√≥n: Entrenamiento Manual (Random Forest)</b></h5>

  - Cargar dataset preprocesado.
  - Permitir ajuste interactivo de hiperpar√°metros (p. ej. `n_estimators`, `max_depth`, `class_weight`).
  - Entrenar modelo (clasificador o regresor seg√∫n el objetivo).
  - Evaluar en conjunto de test: matriz de confusi√≥n, curva ROC, AUC, Accuracy, MAE/RMSE, reporte por clases.
  - Mostrar importancia de variables (`feature_importances_`) y curvas de aprendizaje.
  - Guardar modelo entrenado (`joblib`/`pickle`) y ofrecer descarga.

<h5>1Ô∏è‚É£1Ô∏è‚É£ <b>Opci√≥n: Ver Documentaci√≥n</b></h5>

   - Lectura y procesamiento de `documentacion_tienda_aurelion.md`
   - Contenido organizado en expanders por secciones:
     ‚Ä¢ Contexto y objetivo
     ‚Ä¢ Datasets y metodolog√≠a
     ‚Ä¢ Pseudoc√≥digo
     ‚Ä¢ Diagrama de flujo
   - Visualizaci√≥n adaptativa del flujograma

<h5>1Ô∏è‚É£2Ô∏è‚É£ <b>Interactividad</b></h5>

   - Los **expanders** permiten ocultar o desplegar secciones para una interfaz m√°s limpia.  
   - Los **selectboxes** ofrecen navegaci√≥n din√°mica entre datasets y apartados.  
   - La aplicaci√≥n combina usabilidad y claridad visual para una exploraci√≥n fluida de los datos.

---

### Pseudoc√≥digo

```text
INICIO

1. Configurar la p√°gina de Streamlit:
    - T√≠tulo: "Tienda Aurelion"
    - √çcono de la p√°gina
    - Layout: ancho completo ("wide")

2. Mostrar encabezado principal:
    - Crear dos columnas (1 y 4 proporciones)
    - Columna 1: mostrar logo de la tienda desde ./assets/logo_aurelion.png
    - Columna 2: mostrar t√≠tulo del proyecto y descripci√≥n general

3. Definir funciones de carga y unificaci√≥n:
    FUNCION get_dataset_paths():
        Retornar diccionario con rutas de:
            - clientes.xlsx
            - productos.xlsx
            - ventas.xlsx
            - detalle_ventas.xlsx
            - df_tienda_aurelion.csv

    FUNCION load_dataset(nombre):
        - Obtener rutas mediante get_dataset_paths()
        - SI nombre es "df_tienda_aurelion" y no existe:
            Llamar a load_and_merge_datasets()
        - SI es archivo Excel:
            Leer con pandas.read_excel()
        - SI es archivo CSV:
            Leer con pandas.read_csv()
        - Manejar errores y mostrar advertencias

    FUNCION load_and_merge_datasets():
        - Cargar los 4 datasets Excel
        - Realizar merge progresivo:
            1. clientes + ventas
            2. ventas + clientes
            3. detalle_ventas + productos
            4. merge final
        - Calcular total_venta y convertir fechas
        - Guardar como CSV
        - Retornar DataFrame unificado

4. Definir utilidades de visualizaci√≥n:
    FUNCION save_fig_to_disk(figura, nombre, carpeta="assets/plots"):
        - Crear carpeta si no existe
        - Limpiar nombre del archivo
        - Guardar figura con calidad apropiada

    FUNCION mostrar_fig(figura, ancho=700):
        - Mostrar en Streamlit
        - Opcionalmente guardar en disco
        - Cerrar figura

5. Crear men√∫ lateral con opciones:
    - "Informaci√≥n general"
    - "Estad√≠sticas"
    - "EDA Automatizado"
    - "EDA Diagn√≥stico" 
    - "Ver documentaci√≥n"

6. SI la opci√≥n es "Informaci√≥n general":
    - Mostrar selectbox con datasets disponibles
    - Para el dataset seleccionado mostrar:
        - Fecha y tama√±o del archivo
        - Vista previa (head)
        - Estructura (tipos de columnas)
        - Cantidad de registros

7. SI la opci√≥n es "Estad√≠sticas":
    - Permitir seleccionar dataset
    - Mostrar:
        - Informaci√≥n general del dataset
        - Valores nulos por columna
        - Valores √∫nicos por columna
        - Estad√≠sticas descriptivas
        - Matriz de correlaci√≥n (si hay num√©ricas)
        - Visualizaciones espec√≠ficas seg√∫n el dataset:
            ‚Ä¢ Clientes: distribuci√≥n por ciudad y mes
            ‚Ä¢ Productos: distribuci√≥n de precios y categor√≠as
            ‚Ä¢ Ventas: evoluci√≥n mensual y medios de pago
            ‚Ä¢ Detalle: distribuci√≥n de cantidades e importes

8. SI la opci√≥n es "EDA Automatizado":
    - Cargar/generar df_tienda_aurelion
    - Crear ProfileReport con ydata-profiling
    - Mostrar en Streamlit con st_profile_report

9. SI la opci√≥n es "EDA Diagn√≥stico":
    - Cargar df_tienda_aurelion
    - Verificar unificaci√≥n exitosa
    - Realizar limpieza b√°sica:
        ‚Ä¢ Convertir fechas a datetime
        ‚Ä¢ Renombrar columnas si necesario
        ‚Ä¢ Eliminar columnas duplicadas
    - Generar y guardar visualizaciones:
        ‚Ä¢ Distribuci√≥n de variables num√©ricas
        ‚Ä¢ Matriz de correlaci√≥n
        ‚Ä¢ Series temporales de ventas
        ‚Ä¢ Top productos
        ‚Ä¢ Detecci√≥n de outliers
    - Mostrar interpretaci√≥n de resultados

10. SI la opci√≥n es "Preprocesamiento ML"
    - Seleccionar objetivo (target) y variables predictoras
    - Mostrar y aplicar opciones de preprocesamiento:
      ‚Ä¢ Manejo de nulos: imputaci√≥n (media/mediana/moda)
      ‚Ä¢ Codificaci√≥n de categ√≥ricas: one-hot / ordinal
      ‚Ä¢ Escalado de num√©ricos: StandardScaler / MinMax
      ‚Ä¢ Selecci√≥n de caracter√≠sticas (opcional)
    - Mostrar split train/test configurable (p. ej. 80/20) y semilla
    - Retornar datasets: X_train, X_test, y_train, y_test

11. SI la opci√≥n es "AutoML (Benchmark)"
    - Usar PyCaret (o librer√≠a similar) para benchmarking autom√°tico
    - Pasos:
      - Cargar dataset preprocesado
      - Inicializar setup con target y m√©tricas relevantes
      - Comparar modelos (compare_models)
      - Mostrar top N modelos y m√©tricas (AUC, Accuracy, RMSE seg√∫n caso)
      - Permitir seleccionar mejor modelo y guardar configuraci√≥n

12. SI la opci√≥n es "Entrenamiento Manual (Random Forest)"
    - Cargar dataset preprocesado
    - Permitir selecci√≥n de hiperpar√°metros (n_estimators, max_depth, random_state)
    - Entrenar modelo RandomForestClassifier/Regressor seg√∫n el caso
    - Evaluar modelo en test set (matriz de confusi√≥n, AUC, accuracy, MAE/RMSE)
    - Mostrar interpretaci√≥n de importancia de caracter√≠sticas (feature_importances_)
    - Guardar modelo entrenado (`joblib` / `pickle`) y permitir descarga

13. SI la opci√≥n es "Ver documentaci√≥n":
    - Verificar existencia de documentacion_tienda_aurelion.md
    - SI existe:
        - Leer contenido y dividir en secciones
        - Mostrar cada secci√≥n en expander
        - Mostrar diagrama de flujo centrado
    - SINO:
        - Mostrar advertencia

14. Mostrar pie de p√°gina (footer):
    - Informaci√≥n del Sprint
    - Autor y enlace a LinkedIn

FIN

```

---


### Diagrama del flujo üü°üü°üü°üü°üü°üü°üü°üü°üü°üü°üü°üü°

A continuaci√≥n, se presenta el flujograma del proceso general del proyecto **Tienda Aurelion**.  
Este diagrama ilustra las principales etapas del flujo del programa, desde la carga de los datasets hasta la visualizaci√≥n interactiva de la informaci√≥n en la aplicaci√≥n web.

<p align="center">
  <img src="../assets/flujograma_aurelion.png" alt="Flujograma Tienda Aurelion" width="600">
</p>

---

### Interpretaciones EDA ‚Äì Visualizaciones

Esta secci√≥n describe las principales visualizaciones generadas autom√°ticamente por la aplicaci√≥n, junto con su interpretaci√≥n.
Cada gr√°fico se encuentra guardado en la carpeta plots/ y se muestra en la secci√≥n de estad√≠sticas del dashboard.

#### üî∏ Gr√°fica: distribucion_numericas

A continuaci√≥n, se detallan las explicaciones correspondientes a cada una de las variables analizadas.

| Variable            | Descripci√≥n visual                                                  | Patr√≥n observado                                                                                                                                             | Interpretaci√≥n                                                                                                               |
| ------------------- | ------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------ | ----------------------------------------------------------------------------------------------------------------------------- |
| **cantidad**        | Eje X: cantidad (1 a 5) <br> Eje Y: frecuencia (hasta ~85)          | ‚Ä¢ Las cantidades m√°s frecuentes son 2 y 4, con picos cercanos a 80 y 70 respectivamente. <br> ‚Ä¢ Las dem√°s cantidades (1, 3 y 5) tienen frecuencias similares, alrededor de 60. | Distribuci√≥n discreta y relativamente uniforme, con un pico notable en **cantidad = 2**. La dispersi√≥n es baja.               |
| **precio_unitario** | Eje X: precio_unitario (0 a 5000) <br> Eje Y: frecuencia (hasta 60) | ‚Ä¢ Asim√©trica, con concentraci√≥n entre **1500 y 2500**. <br> ‚Ä¢ Pico cerca de **2000**. <br> ‚Ä¢ Pocos valores en extremos (<500 y >4000).                       | La mayor√≠a de los productos se venden en un rango medio de precios, con pocos productos en rangos muy altos.         |
| **total_venta**     | Eje X: total_venta (0 a 25000) <br> Eje Y: frecuencia (hasta 60)    | ‚Ä¢ Distribuci√≥n **sesgada a la derecha**. <br> ‚Ä¢ Alta concentraci√≥n entre **0 y 10,000**, con pico entre **3,000‚Äì5,000**. <br> ‚Ä¢ Pocos casos >20,000.         | La mayor√≠a de las ventas son bajas o moderadas; las muy altas son raras, indicando posibles *outliers* en el extremo derecho. |


#### üî∏ Gr√°fica: correlacion

**Variables analizadas:**
* cantidad
* precio_unitario
* total_venta

**Principales resultados:**
1. cantidad vs precio_unitario
- Correlaci√≥n: -0.074 (muy baja y negativa). No existe relaci√≥n significativa entre la cantidad vendida y el precio unitario. Es decir, vender m√°s unidades no implica que el precio sea mayor o menor.

2. cantidad vs total_venta:
- Correlaci√≥n: 0.6 (moderada y positiva). A mayor cantidad, tiende a aumentar el total de venta, lo cual es l√≥gico porque m√°s unidades generan m√°s ingresos, aunque no es una relaci√≥n perfecta.

3. precio_unitario vs total_venta:
- Correlaci√≥n: 0.68 (moderada-alta y positiva). El precio unitario tiene una influencia importante en el total de venta. Productos m√°s caros tienden a generar ventas totales m√°s altas, incluso si la cantidad no var√≠a mucho.

#### üî∏ Gr√°fica: ventas_total_por_mes

El gr√°fico muestra la evoluci√≥n de las ventas mensuales entre enero 2024 y junio 2024.
Se observa una tendencia fluctuante, con una ca√≠da marcada en abril y una recuperaci√≥n fuerte en mayo.

Resultados clave:

* **M√°ximo**
  - Mes: mayo 2024 - Valor: 561,832
  - Este fue el mejor mes en ventas, superando el promedio por un amplio margen.

* **M√≠nimo**
  - Mes: abril 2024 - Valor: 251,524
  - Abril fue el peor mes, con ventas muy por debajo del promedio.

* **Promedio**
  - L√≠nea horizontal: 441,903 
  - Tres meses (enero, mayo y junio) estuvieron por encima del promedio, mientras que febrero, marzo y abril quedaron por debajo.

Tendencias espec√≠ficas:
- Enero (529,840): Buen inicio, por encima del promedio.
- Febrero y Marzo: Descenso progresivo (407,041 ‚Üí 388,263).
- Abril: Ca√≠da abrupta al m√≠nimo (251,524).
- Mayo: Recuperaci√≥n fuerte al m√°ximo (561,832).
- Junio: Ligera baja respecto a mayo, pero sigue alto (512,917).

> Las ventas son vol√°tiles, con un m√≠nimo cr√≠tico en abril y un m√°ximo en mayo.
El promedio indica que la tienda tiene un buen desempe√±o general, pero necesita analizar qu√© caus√≥ la ca√≠da en abril y el repunte en mayo (promociones, estacionalidad, campa√±as).

#### üî∏ Gr√°fica: relacion_cantidad

Diagrama de dispersi√≥n con:
- Eje X: cantidad (de 1 a 5 unidades).
- Eje Y: total_venta (hasta 25,000).
- Incluye una l√≠nea de tendencia ascendente y un valor de correlaci√≥n: 0.60.

Resultados clave:
1. Correlaci√≥n positiva moderada (0.60): Indica que a mayor cantidad vendida, mayor es el total de venta, aunque no es una relaci√≥n perfecta.
Esto es l√≥gico: m√°s unidades generan m√°s ingresos, pero hay variabilidad por el precio unitario.

2. Patr√≥n de dispersi√≥n: Para cada cantidad (1 a 5), hay una amplia dispersi√≥n en el total de venta.
Ejemplo:
   - Cantidad = 1 ‚Üí ventas entre ~1,000 y ~5,000.
   - Cantidad = 5 ‚Üí ventas entre ~5,000 y >20,000.
El precio unitario influye mucho en el total, incluso con la misma cantidad.

3. Tendencia general: La l√≠nea de regresi√≥n muestra un incremento consistente: m√°s cantidad tiende a aumentar el total de venta.

> Existe una relaci√≥n clara entre cantidad y total de venta, pero no es determinante por s√≠ sola.
El precio unitario es un factor adicional que explica la dispersi√≥n.
Para aumentar ventas totales, incrementar la cantidad ayuda, pero tambi√©n es clave considerar el mix de productos y precios.

#### üî∏ Gr√°fica: outliers

A continuaci√≥n se resumen los resultados de los gr√°ficos de outliers agrupados por tipo de variable.

| Variable            | Rango observado                     | Mediana / Forma de la distribuci√≥n                                                    | Interpretaci√≥n                                                                                          |
|--------------------|--------------------------------------|----------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------|
| **cantidad**        | 1 a 5                                | Mediana ‚âà 3; distribuci√≥n sim√©trica; sin outliers relevantes                           | Las cantidades vendidas suelen estar entre 2 y 4; pedidos consistentes sin valores at√≠picos significativos. |
| **precio_unitario** | ~500 a 5000                          | Mediana ‚âà 2500; distribuci√≥n equilibrada; algunos puntos fuera del rango               | Los precios se concentran en el rango medio, aunque existen productos con precios extremos.              |
| **total_venta**     | 0 a >20,000                          | Mediana ‚âà 8000; distribuci√≥n sesgada a la derecha; m√∫ltiples outliers                  | La mayor√≠a de las ventas son bajas o medias, pero existen transacciones extraordinarias que elevan el m√°ximo. |


---

### Preprocesamiento para Machine Learning

1Ô∏è‚É£ **Objetivo**
    
Preparar el dataset para entrenar modelos de clasificaci√≥n que predigan el nivel de demanda de cada producto a partir de m√©tricas agregadas de ventas.

2Ô∏è‚É£ **Metodolog√≠a aplicada**

üî∏ Agrupaci√≥n por producto
  - Dataset original: 343 transacciones individuales
  - Dataset agrupado: 95 productos √∫nicos

üî∏ Variables creadas:
  - `total_unidades`: Suma de unidades vendidas por producto
  - `total_ventas`: Ingreso total generado por producto
  - `cant_transacciones`: N√∫mero de ventas √∫nicas
  - `precio_promedio`: Precio unitario promedio
  - `ventas_por_transaccion`: Ingreso promedio por transacci√≥n
  - `unidades_por_transaccion`: Unidades promedio por transacci√≥n

üî∏ **Variable objetivo**: `Nivel de demanda`

  Basada en percentiles de `total_unidades`:

  | Categor√≠a     | Rango         | Cantidad de productos |
  | ------------- | ------------- | --------------------- |
  | **Baja (0)**  | ‚â§ 8 unidades  | 38                    |
  | **Media (1)** | 8‚Äì12 unidades | 27                    |
  | **Alta (2)**  | > 12 unidades | 30                    |

  Distribuci√≥n balanceada y adecuada para clasificaci√≥n multiclase.

üî∏ Transformaciones aplicadas
  - One-Hot Encoding de `categoria_corregida` (10 categor√≠as)
  - Eliminaci√≥n de `nombre_producto` por alta cardinalidad
  - Mapping del target:
     - baja ‚Üí 0
     - media ‚Üí 1
     - alta ‚Üí 2

3Ô∏è‚É£ **Resultados del preprocesamiento**
   
  üîπ Consistencia verificada: la suma original (1016) coincide con la suma agrupada (1016).

  üîπ Balance de clases: Distribuci√≥n equilibrada (30 / 27 / 38 productos por categor√≠a)

  üîπ Dataset final: 95 productos √ó 18 variables listas para el modelado.

---

### AutoML: Benchmarking con PyCaret

1Ô∏è‚É£ **Objetivo**
  
Identificar autom√°ticamente el modelo de clasificaci√≥n con mejor desempe√±o para predecir el nivel de demanda de productos.

2Ô∏è‚É£ **Configuraci√≥n del experimento**

El experimento se ejecut√≥ con PyCaret utilizando las siguientes configuraciones:
  - **Normalizaci√≥n**: Activada
  - **Remoci√≥n de multicolinealidad**: Activada  
  - **Split train/test**: 69%/31%
  - **Cross-validation**: 10 folds
  - **Seed (session_id)**: 789
  - **M√©trica principal (sort)**: AUC

3Ô∏è‚É£ **Resultados de la comparaci√≥n**

Los modelos fueron ordenados por AUC (m√©trica seleccionada en `compare_models`).

  üî∏ **Top 5 modelos seg√∫n AUC**

  | Modelo | Accuracy | AUC | F1-Score | Tiempo (s) |
  |--------|----------|-----|----------|------------|
  | Random Forest | 0.9857 | 0.9971 | 0.9848 | 0.120 |
  | AdaBoost | 0.9857 | 0.9943 | 0.9848 | 0.070 |
  | Gradient Boosting | 0.9857 | 0.9943 | 0.9848 | 0.119 |
  | Decision Tree | 0.9857 | 0.9900 | 0.9848 | 0.023 |
  | LightGBM | 0.9381 | 0.9943 | 0.9270 | 0.127 |

4Ô∏è‚É£ **Modelo seleccionado**
   
  **Random Forest Classifier** - Mejor desempe√±o general con:
    
  - **Accuracy**: 98.57%
  - **AUC**: 99.71% 
  - **F1-Score**: 98.48%

  üî∏ **Interpretaci√≥n**
    
  - Los modelos de ensemble (Random Forest, AdaBoost, Gradient Boosting) dominan el ranking
  - El desempe√±o general es excelente, con valores de AUC superiores al 99%.
  - Los tiempos de entrenamiento fueron muy bajos, adecuados para datasets peque√±os como este.
  - El modelo seleccionado presenta una excelente capacidad predictiva y estabilidad.

---

### Entrenamiento Manual: Random Forest

<h5>1Ô∏è‚É£ <b>Objetivo</b></h5>
    
Implementar manualmente un modelo Random Forest Classifier para predecir el nivel de demanda de productos, evaluando su desempe√±o mediante validaci√≥n cruzada, m√©tricas de test, curva ROC multiclase, matriz de confusi√≥n, curva de aprendizaje e importancia de variables.

Este enfoque permite obtener un modelo transparente, reproducible y completamente controlado por el analista, ideal para evaluar real capacidad de generalizaci√≥n.

<h5>2Ô∏è‚É£ <b>Configuraci√≥n del modelo</b></h5>

El modelo fue configurado manualmente en la aplicaci√≥n Streamlit con los siguientes par√°metros:

üîπ Algoritmo

- **Random Forest Classifier**

üîπ Hiperpar√°metros seleccionados

- **n_estimators**: 200
- **max_depth**: 15
- **min_samples_split**: 5
- **min_samples_leaf**: 2
- **max_features**: "sqrt"
- **class_weight**: "balanced"
- **random_state**: 789

üîπ Configuraci√≥n del entrenamiento

- **Test size**: 31% (id√©ntico a PyCaret para una comparaci√≥n justa)
- **Balanceo de clases**: Activado
- **Validaci√≥n cruzada**: 5 folds (definido din√°micamente seg√∫n el tama√±o del dataset)
- **Dataset usado**: 95 productos procesados

<h5>3Ô∏è‚É£ <b>M√©tricas de evaluaci√≥n</b></h5>

  üî∏ **Validaci√≥n Cruzada (5 folds)**
  
  Durante la validaci√≥n cruzada, el modelo obtuvo:

  - **Accuracy promedio**: 0.6526
  - **F1-Score promedio**: 0.6320

  Estos valores reflejan un rendimiento moderado, adecuado para un dataset peque√±o.
  
  üî∏ **M√©tricas en el Conjunto de Test**
    
  | M√©trica | Valor |
  |---------|-------|
  | Accuracy | 0.6000 |
  | Precision | 0.5857 |
  | Recall | 0.6000 |
  | F1-Score | 0.5900 |

  El modelo mantiene consistencia entre validaci√≥n cruzada y test, indicando  comportamiento estable, aunque con margen de mejora.
  
  üî∏ **Curva ROC Multiclase (One-vs-Rest)**
  
  - **AUC Macro**: 0.8433
  - **Clase 0 (Baja demanda)**: AUC = 0.92
  - **Clase 1 (Media demanda)**: AUC = 0.75  
  - **Clase 2 (Alta demanda)**: AUC = 0.86 

  La clase ‚ÄúMedia‚Äù es la m√°s dif√≠cil de separar, algo esperable por su posici√≥n   intermedia entre ‚ÄúBaja‚Äù y ‚ÄúAlta‚Äù.

<h5>4Ô∏è‚É£ <b>An√°lisis de resultados</b></h5>

  üî∏ **Matriz de Confusi√≥n**
  
  La matriz evidencia:

  - Buen desempe√±o en clase 0 (baja) y clase 2 (alta).
  - Alta confusi√≥n en la clase 1 (media), consistente con el Recall=0.333 observado.

  Este comportamiento se debe a la naturaleza del problema: la clase media es m√°s ambigua y con menor soporte.

  üî∏ **Importancia de variables**
    
  **Top 5 features m√°s importantes**:
    
  1. `cant_transacciones` (0.4151)
  2. `id_producto` (0.1534) 
  3. `precio_promedio` (0.1517)
  4. `ventas_por_transaccion` (0.1355)
  5. `categoria_Higiene personal` (0.0224)

  Los resultados destacan la importancia del volumen de operaciones y precio promedio, variables clave para entender la demanda.

<h5><b>Classification Report por clase</b></h5>

  | Clase | Precision | Recall | F1-Score |
  |-------|-----------|--------|----------|
  | Baja (0) | 0.714 | 0.833 | 0.769 |
  | Media (1) | 0.375 | 0.333 | 0.353 |
  | Alta (2) | 0.625 | 0.556 | 0.588 |

  La clase ‚ÄúMedia‚Äù contin√∫a siendo la m√°s d√©bil; se beneficiar√≠a de m√°s datos o t√©cnicas de oversampling futuro.

<h5><b>Curva de aprendizaje</b></h5>

La curva de aprendizaje muestra:
- Brecha moderada entre entrenamiento y validaci√≥n
- Sin se√±ales de overfitting extremo
- Mejoras observables al aumentar el tama√±o del dataset

Conclusi√≥n: el modelo generaliza razonablemente bien, pero ser√≠a beneficioso entrenarlo con m√°s datos.

<h5>5Ô∏è‚É£ <b>Conclusiones generales</b></h5>

**Comparativa: AutoML vs Random Forest Manual**
  
  | Aspecto | AutoML (PyCaret) | RF Manual |
  |---------|------------------|-----------|
  | Accuracy Test | 98.57% | 60.00% |
  | AUC Macro | 99.71% | 84.33% |
  | Configuraci√≥n | Autom√°tica | Manual optimizado |
  | Interpretabilidad | Media | Alta |
  | Generalizaci√≥n | Potencial overfitting | M√°s Realista |

 Interpretaci√≥n

- PyCaret logra m√©tricas extremadamente altas gracias a un preprocesamiento y tuning intensivo.
- El RF Manual, aunque menos preciso, es m√°s interpretable y m√°s honesto respecto a la generalizaci√≥n real.
- En datasets peque√±os como este, el modelo manual suele reflejar mejor el rendimiento esperado en producci√≥n.

<h5>6Ô∏è‚É£ <b>Recomendaciones para producci√≥n</b></h5>
    
1. **Modelo sugerido**: 
    - Random Forest Manual ‚Üí Mayor generalizaci√≥n y transparencia.
    - PyCaret puede usarse como benchmark o para an√°lisis exploratorio.
2. **Variables clave**:
    - Cantidad de transacciones
    - Precio promedio
    - Ventas por transacci√≥n

3. **Puntos a monitorear**:
    - Desempe√±o sobre la clase Media
    - Distribuciones de demanda ante cambios estacionales

4. **Mejoras futuras**
    - Recolectar m√°s datos
    - Aplicar oversampling (SMOTE)
    - Probar embeddings o t√©cnicas de reducci√≥n de dimensionalidad
    - Ajustar hiperpar√°metros adicionales

<h5>7Ô∏è‚É£ <b>Impacto para el Negocio</b></h5>

El modelo desarrollado permite:

- Identificar productos de alta rotaci√≥n para evitar ruptura de stock
- Detectar baja demanda para optimizar compras e inventario
- Planificar abastecimiento con mayor precisi√≥n
- Incrementar rentabilidad ajustando √≥rdenes seg√∫n nivel de demanda esperado

Este enfoque ayuda a tomar decisiones estrat√©gicas en gesti√≥n de inventario, compras y planificaci√≥n comercial.

---


